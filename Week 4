Continuing Research on embodied cognition and interaction with musical instruments: 
"Of Epistemic Tools: musical instruments as cognititve extensions" by Thor Magnusson
Key Points:
-learning an acoustic instrument/creating one is very different from creating a digital instrument. an ascoustic instrument requires the user
to learn how to hold it and through emobdied, motor learning develops a different relationship from that of a digital instrument,
which is more calculated and mathematical. 
-"embodiiment relationship" - the tool is an extension of the body
-"hermeneutic relationship" - tool is external and we have to interpret information from it (like a text, something we have to read 
and acquire knoweldge about in the process"
//key point: digital instruments an extension of the mind rather than body

since it's an extension of the mind, at its core it's made of "symbolic instructions written for the meta-machine(computer)". Functionality 
is always explicitly determined for the digital interface(less inherent creativity, unlike with acoustic instruments)

Musicians learn their insturment not explicitly, but through the actual act of performing the instrument, unlike in languages or math 
where there are clear rules one has to learn, and symbols to understand. 
How does the digital insturment manifest itself in the body? 
objects and instruments are external playground for thinking (sticky notes, calculators, graphs, etc.
technolgoies in music are political, material, scrited (influenced by culture and those creating it) so they are *never neutral*
always biased from the persepctives of those who created it. 

instruments inherently tell us the way they are to be used. (p.171) * // are they then created in a way to garner a certain output?

understanding music --> black box. hard to explain what is going on. the more opaque it is, the more science and tehcnology succeed(the better
the person using it is at performing it)
hard to verbally explain. their knowledge is "sepctrochemical" and detached. 

acoustic instruments: allow for exploration of sonic sounds without explicit or theoretical instruction. grouned in human physique in design.
digital instruments: "no natural mapping between gesture and sound" (ex: force sensitivity, more complex, more in-between steps to get end result)

"expressive closure" (digial instruments' encapsulated musical culture) vs. "explorative openings" (acoustic instruments)
digital instruments = an act of fossilisation. things are set in stone as digital instruments evolve, rather than constant reimagination of acoustic instruments


acoustic instruments: bottom up exploration of acoustic properties of materials used (sound generated and used given to us free by nature_
digital instruments: top down creation, dependent on knoweldge of programming, HCI, user interfaces. understood symbolically and not intuitively
learned through habit, theory does not need to be understood. not very chaotic (bc it is designed to be easy to use)

"software has agency and necessarily inheres more cultural specifications than any acoustic instrument"


"Musical Gestures and Embodied Cognition" - Mark Leman
"Music is based on a tight relationship between sounds and experiences that are mediated by the body."
Goal is to control the nature of the phenomenon for music education
Tools, like DJogger takes the tempo of walking and gives music at same tempo of walking tempo, helping users match the pace. Making
it easier to stay on pace. 
There are two types of loops (action perception coupling system): the sensorimotor loop and action-perception loop
sensorimotor loop: motor activity driven by sensory input from environemnt (low-level)
action-perception loop(for performing intsruments): gesture/action reperoire (high-level)
can run in parallel:
sensorimotor loop maintains ctonrol of mouth and breath in relation to sound production
action-perception loop uses repretoire of learned fingering patterns to control *expressive* production of sound. 

other way around:
when percieving sound, rely on learned knowledge to assume action from sound. (reason for embodiment)
ex: when a sound is heard, people will react in way they know sound is produced (say, air guitar) and when it is an abstract sound
person will act in relation to approximations of how sound is produced. 


Project Ideas: 
1. how to make digital instruments (like xpand2 in pro tools, etc. to be more easily accesible.) by performing usability testing
- various users at different skill sets
- interviews with people who actually perform instruments vs. people who don't and try to learn digital instruments
- maybe do some research regarding DJ's?

2. researching how people interact with virtual instruments vs. acoustic instruments
- background of sound engineers, how they learned digitally vs. acoustically
- interviewing people of music background vs. non-music background and see how they learn (in a natural environment)
- ask people about their relationships with their instrument over time. 
